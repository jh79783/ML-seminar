# 2. 이진 판단

0 또는 1 둘 중 하나를 선택하는 문제는 직선으로 표현하는데 적절하지 않습니다. 이러한 문제들을 해결해주는 비선형적인 함수가 필요했는데, 그 함수가 바로 시그모이드 함수입니다. 또한 1장에서는 cost function으로 MSE를 사용하였는데, 이 문제에서는 교차 엔트로피를 사용하였습니다.

## 시그모이드 함수

![](C:\workspace\ML\image\sigmoid.png)

시그모이드 함수는 S자 처럼 생긴 비선형 그래프이며, 범위에 제한이 없는 임의의 실수값을 입력으로 받아 확률값 범위에 해당하는 0과 1사이의  값을 출력하는 함수입니다. 표시는 다음과 같습니다.
$$
\sigma(x)
$$
이때의 입력값은 어떤 확률값의 로짓(logit)이라고 표현이라고 간주합니다.

>로짓(logit) : 실제 표현하려는 값을 로그값으로 나타낸 것.

즉, 시그모이드 함수는 로짓값을 확률값으로 변환해주는 함수입니다.
로짓값을 사용하는데는 더 넓은 범위를 간단히 표현할 수 있고 변화량보다 변화 비율 관점에서 더 민감하게 포착할 수 있다는 점 때문입니다. 하지만 로짓값은 상대적이기 때문에 하나의 값으로는 정확한 의미를 알 수 없고, 비교가 가능한 로짓값이 있어야 합니다.

시그모이드 함수는 다음과 같이 정의됩니다.
$$
\alpha(x)=\frac{1}{1+e^{-x}}
$$
또한 시그모이드 함수의 미분은 다음 과정을 거쳐 매우 간단한 식이 됩니다.
$$
\alpha^{'}(x)=\frac{-(1+e^{-x})^{'}}{(1+e^-x)^2}\\=\frac{e^{-x}}{(1+e^{-x})^2}\\=\frac{(1+e^{-x})-1}{(1+e^{-x})^2}\\=\frac{1}{1+e^{-x}}(1-\frac{1}{1+e^{-x}})\\=\alpha(x)(1-\alpha(x))
$$

## 확률 분포와 정보 엔트로피

정보 엔트로피는 확률 분포의 무질서도나 불확실성 혹은 정보 표현의 부담 정도를 나타냅니다.
50%확률로 일어나는 사건의 결과는 2가지로, 1비트(0, 1)로 표현이 가능하며 25%라면2비트(00, 01, 10, 11)로 가능합니다. 따라서 총 m%확률 사건에서 한개의 사건을 표현하는데 필요한 최소한의 비트 수는 다음과 같으며, 이를 **정보량**이라고 합니다.
$$
\log_2m
$$
정보량은 확률이 균일하지 않은 확률 분포에도 적용할 수 있습니다.
$$
\frac{1}{a_1}\log_2a_1+\frac{1}{a_2}\log_2a_2+...+\frac{1}{a_m}\log_2a_m\\=\sum^m_{i=1}\frac{1}{a_i}\log_2a_i=정보량
$$
위의 정보량의 식을 주어진 확률 분포에 대한 정보를 엔트로피라고 하며 H로 표시합니다.
또한 H는 확률 분포의 역수 관계를 이용하여 다음과 같이 표현할 수 있습니다.
$$
확률 분포:p_i=\frac{1}{a_i}\\H=\sum^m_{i=1}p_i\log_2\frac{1}{p_i}\\=\sum^m_{i=1}p_i(-\log_2p_i)\\=-\sum^m_{i=1}p_i\log_2p_i
$$

## 확률 분포의 추정과 교차 엔트로피

H인 정보 엔트로피는 정보량의 기댓값이라고 할 수 있습니다.
확률 p를 갖는 항의 정보량은 다음과 같이 표현할 수 있습니다.
$$
-\log{p_i}
$$
따라서 H는 각 경우의 발생 확률에 따라 정보량의 가중평균을 구한다고 해석할 수 있습니다.
따라서 H가 정보량의 기댓값에 해당합니다.

확률 분포 Q에 따른 정보량을 확률 분포 P에 따라 일어날 때를 교차 엔트로피로 정의할 수 있습니다.
$$
H(P,Q)=-\sum{p_i}\log{q_i}
$$
위의 식이 P에 대한 Q의 교차 엔트로피로 정의한 것입니다.

## 시그모이드 교차 엔트로피와 편미분

학습 데이터의 정답이 z, 로짓값 x를 출력하였다고 했을때, 정답이 나타내는 확률 분포와 신경망이 추정하는 확률 분포 사이의 교차엔트로피는 다음과 같습니다.
$$
H=x-xz+log(1+e^{-x})\\z=0:H=x+log(1+e^{-x})=x-\log\sigma(x)\\z=1:H=log(1+e^{-x})=-\log\sigma(x)
$$
시그모이드 함수에 대한 교차 엔트로피 편미분은 다음과 같이 계산됩니다.
$$
\frac{\sigma{H}}{\sigma{x}}=\frac{\sigma}{\sigma{x}}(x-xz+\log{(1+e^-x)})\\=1-z+\frac{(1+e^{-x})^{'}}{1+e^{-x}}\\=1-z+\frac{-e^{-x}}{1+e^{-x}}\\=-z+\frac{1}{z+e^{-x}}\\=-z+\sigma(x)
$$
