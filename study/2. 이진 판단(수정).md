# 이진 판단

이진 판단은 0 또는 1 둘 중 하나를 선택하는 문제입니다. 퍼셉트론의 선형 연산은 0과 1 사이의 값으로 제한하는 것이 불가능 하기때문에 0과 1사의 값인 확률값의 성질을 사용할 수 있게 만들어 주는 시그모이드 함수를 사용하게 되었습니다. 또한, 0 과 1 사이의 값을 사용하기 때문에 확률 분포가 얼마나 다른지 표현해주는 교차 엔트로피를 도입하게 되었습니다.

## 시그모이드 함수



![](C:\workspace\ML\image\sigmoid.png)

시그모이드 함수는 S자 처럼 생긴 비선형 그래프 입니다. 
이 함수는 범위에 제한이 없는 실수값을 입력으로 받으며 0과 1사이의 값을 출력하게 됩니다.
시그모이드 함수의 표시 및 정의는 다음과 같습니다
$$
\alpha(x)=\frac{1}{1+e^{-x}}
$$
시그모이드 함수의 입력값 x는 확률값의 로짓(logit) 표현이라고 간주합니다.

> 로짓(logit) : 실제 표현하려는 값을 로그값으로 나타낸 것.

따라서 시그모이드 함수는 로짓값을 확률값으로 변환해주는 함수입니다.
로짓값을 사용하는 이유는 더 넓은 범위를 간단히 표현가능하기 때문입니다.
하지만 로짓값은 상대적이기 때문에 하나의 값으로는 정확한 의미를 알 수 없고, 비교가 가능한 로짓값이 있어야 합니다.

역전파를 사용하기 위해 시그모이드 함수의 미분이 필요한데, 시그모이드 함수의 미분은 다음 과정을 거쳐 매우 간단하게 변하게 됩니다.
$$
\alpha^{'}(x)=\frac{-(1+e^{-x})^{'}}{(1+e^-x)^2}\\=\frac{e^{-x}}{(1+e^{-x})^2}\\=\frac{(1+e^{-x})-1}{(1+e^{-x})^2}\\=\frac{1}{1+e^{-x}}(1-\frac{1}{1+e^{-x}})\\=\alpha(x)(1-\alpha(x))
$$

## 확률 분포와 정보 엔트로피

일반적인 엔트로피는 불확실성을 의미합니다. 이를 정보에 적용하여 정보를 얻을 수 있는 가능성(정보의 불확실성)을 표현하는 정보 엔트로피를 도입하게 되었습니다.
정보 엔트로피는 의미있는 정보를 얻을 수 있는 양을 말합니다.(정보량)

예로 동전 던지기가 있습니다.
동전은 앞면, 뒷면의 확률이 각각 0.5로 이때의 엔트로피는 최대입니다. 왜냐하면 시행의 결과가 예측이 불가능 하기 때문입니다. 이러한 정보를 얻어내는 시행을 하여 시행 결과의 분포에 대한 의미있는 정보를 수집할 수 있습니다.

또 다르게, 한쪽 면이 나올 확률이 0.9로 편향 되어있다면 정확하지는 않지만 어느정도 예측은 가능합니다. 따라서 이것은 의미 있는 정보라고 보기는 힘들어집니다. 이때의 엔트로피는 낮아지게 됩니다. 의미있는 정보를 얻을 수 있는 양이 줄어들었기 때문입니다.

따라서 정보량의 가중평균을 수식으로 살펴보면 다음과 같습니다.
$$
\frac{1}{a_1}\log_2a_1+\frac{1}{a_2}\log_2a_2+...+\frac{1}{a_m}\log_2a_m\\=\sum^m_{i=1}\frac{1}{a_i}\log_2a_i
$$


확률을 수식으로 보면 다음과 같이 나타낼 수 있습니다.
$$
p_i = \frac{1}{a_i}
$$
주어진 확률 분포에 대한 정보를 엔트로피라고 하며 이를 H로 표시합니다.
또한, H는 확률 분포의 역수 관계를 이용해 다음과 같이 표현할 수 있습니다.
$$
H=\sum^m_{i=1}p_i\log_2\frac{1}{p_i}\\=\sum^m_{i=1}p_i(-\log_2p_i)\\=-\sum^m_{i=1}p_i\log_2p_i
$$

## 교차 엔트로피

Q의 정보량을 P에 따라 일어날 때를 교차 엔트로피라고 정의할 수 있습니다.
Q는 시행결과 예측(예측값)이라고 볼 수 있으며, P는 경우의 수(정답값) 라고 볼 수 있습니다.
따라서 Q에 따른 P에 대한 교차엔트로피 수식은 다음과 같습니다.
$$
H(P,Q)=-\sum{p_i}\log{q_i}
$$
교차 엔트로피는 예측값이 실제값과 맞는경우 0으로 수렴하게 되며, 값이 다를경우 무한대로 발산하게 됩니다.
따라서 교차 엔트로피를 loss function으로 두어 값이 최소화 되는 방향으로 학습이 진행됩니다.

## 시그모이드 교차 엔트로피와 편미분

학습 데이터의 정답이 z, 로짓값 x를 출력하였다고 했을때, 정답이 나타내는 확률 분포와 신경망이 추정하는 확률 분포 사이의 교차엔트로피는 다음과 같습니다.
$$
H=x-xz+log(1+e^{-x})\\z=0:H=x+log(1+e^{-x})=x-\log\sigma(x)\\z=1:H=log(1+e^{-x})=-\log\sigma(x)
$$
또한 역전파를 사용하기 위한 시그모이드 함수에 대한 교차 엔트로피 편미분은 다음과 같이 계산됩니다.
$$
\frac{\partial{H}}{\partial{x}}=\frac{\partial}{\partial{x}}(x-xz+\log{(1+e^-x)})\\=1-z+\frac{(1+e^{-x})^{'}}{1+e^{-x}}\\=1-z+\frac{-e^{-x}}{1+e^{-x}}\\=-z+\frac{1}{z+e^{-x}}\\=-z+\sigma(x)
$$

## 시그모이드 함수의 문제점

시그모이드 함수에서 입력값이 -1000과 같이 나오게 된다면 문제점이 발생합니다.
$$
e^{1000}=inf
$$
시그모이드 함수 계산 과정에서 위와 같은 문제가 발생하게 됩니다. 따라서 다음과 같아집니다.
$$
\alpha(-1000)=\frac{1}{1+e^{-(-1000)}}\\=\frac{1}{inf}\\=0
$$
시그모이드 함수 계산 결과 0이 나오기 때문에 결과값이 다음으로 전달되지 않아 **W**가 업데이트 되지 않아 학습이 되지 않습니다.

> 기울기가 잘 전달되지 않는 기울기 소실(Vasnishing Gradient) 문제

이는 교차 엔트로피에서도 마찬가지로 작용하게 되어 *H*의 값이 제대로 구해지지 않게 됩니다.
이를 해결하기 위해 ReLU라는 것을 사용하게 됩니다.
구현 코드는 매우 간단합니다.
$$
f(x)=max(0,x)
$$
ReLU 함수는 다음과 같은 모양입니다.

![](C:\workspace\ML\image\relu.jpg)

위의 그래프를 보게되면 음수를 입력하게 되면 0을 출력하게 되며, 양수를 입력하면 입력값 그대로를 반환하게 됩니다.
즉, ReLU 함수는 특정 양수값에 수렴하지 않아 시그모이드보다 더 잘 작동하게 됩니다.
또한 어떠한 연산이 필요하지 않은 단순한 임계값이기 때문에 속도도 더 빠릅니다.