# 3.6 결정 트리 만들기

## 결정 트리

결정 트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예/아니오 질문 목록을 학습한다는 뜻이다. 머신러닝에서는 이러한 질문들을 테스트 라고 한다. 이때의 테스트는 모델이 잘 만들어 졌는지 테스트할 때 사용하는 데이터와는 다르다.

보통 데이터는 예/아니오 형태의 특성으로 구성되지 않고 연속된 특성으로 구성된다. 연속적인 데이터에 적용할 테스트는 "i는 값 a보다 큰가?"와 같은 형태를 띈다.

트리를 만들 때 알고리즘은 가능한 모든 테스트에서 타깃값에 대해 가장 많은 정보를 가진 것을 고른다.

붓꽃 데이터로 트리를 만들면 아래와 같은 트리가 만들어진다.

![](https://raw.githubusercontent.com/jh79783/ML-seminar/master/image/tree.png)

맨위 노드를 보면 petal width <= 0.75라고 되어있다. 이는 데이터 셋을 petal width = 0.75에서 나누는 것이 가장 많은 정보를 포함하고 있다는 것이다. 이 직선이 나타내는 0.75의 테스트에서 분기가 일어나게 되고 이 테스트를 통과하면 왼쪽으로 그렇지 못하면 오른쪽으로 할당된다. 왼쪽 노드는 완벽하게 분류가 되어서 두번째 클래스에만 값이 들어있지만 오른쪽 노드의 경우 값이 완벽하게 분류되지 않아 두번째와 세번째 클래스에 값이 들어있다. 이와 같은 결정경계는 아래의 그림으로 확인할 수 있다.

![](https://raw.githubusercontent.com/jh79783/ML-seminar/master/image/index.png)

이렇게 반복된 프로세스는 각 노드가 테스트를 하나씩 가진 이진 결정 트리를 만들게 된다. 또한 각 테스트는 하나의 특성에 대해서만 이루어지므로 나누어진 영역은 항상 축에 평행하다.

모든 노드를 순수노드가 될 때까지 진행하게 되면 매우 복잡해지고 훈련 데이터에 과대적합이 된다. 따라서 가지치기를 하거나 트리의 최대깊이를 제한하기, 분할하기 위한 포인트의 최소 개수를 지정하는 것이다.

가지치기는 두개로 나뉘는데 사전가지치기와 사후가지치기로 나뉜다. 사전가지치기는 트리 생성을 일찍 중단 하는 것이고 사후가지치기는 트리를 만든 후 데이터 포인트가 적은 노드를 삭제하거나 병합하는 방법이다.

여기서 사용한 결정 트리는 사전가지치기만을 지원한다.

최대 깊이를 설졍하는 방법은 

```python
tree = DecisionTreeClassifier(criterion='gini', 
                              max_depth=4, 
                              random_state=1)
```

여기서 max_depth의 숫자를 정해주면 된다.

이렇게 결정 트리를 만들 수 있다. 결정 트리는 계산복잡성 대비 높은 예측 성능을 낼 수 있고 변수 단위로 설명력을 지닌다는 장점이 있지만 데이터 축에 수직이여서 특정 데이터에만 잘 작동할 수 있다는 단점이 있다. 이를 극복하기 위해 '랜덤 포레스트' 모델이 등장하였다. 랜덤 포레스트는 결정 트리를 여러개 만들어 그 결과를 종합해 예측 성능을 높이는 방법이다.

## 랜덤 포레스트

랜덤 포레스트는 같은 데이터에 결정트리를 여러 개 동시에 적용하는 것이다. 동일한 데이터로부터 30개 이상의 데이터 셋을 만들어 각각 결정트리를 적용한 뒤 학습 결과를 취합하는 방식으로 작동한다. 단 각각의 나무들은 전체 변수 중 일부만 학습을 하게 된다. -> 개별 트리들이 데이터를 바라보는 관점을 다르게해 다양성을 높이기 위해서.

```python
forest = RandomForestClassifier(criterion='gini',
                                n_estimators=25, 
                                random_state=1,
                                n_jobs=2)
```

랜덤 포레스트는 위와 같이 사용된다.

n_estimators는 생성할 결정트리의 개수k의 값이다. 

n_jobs는 학습을 수행하기 위해 cpu 코어 2개를 병렬적으로 활용하는 의미이다.

![](https://raw.githubusercontent.com/jh79783/ML-seminar/master/image/forest.png)

붓꽃 데이터를 사용하면 위와 같이 그려진다.